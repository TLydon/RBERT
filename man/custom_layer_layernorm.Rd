% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tf2-layer_layernorm.R
\name{custom_layer_layernorm}
\alias{custom_layer_layernorm}
\title{Custom Layer: Layer Normalization}
\source{
\url{https://arxiv.org/pdf/1607.06450.pdf}
}
\usage{
custom_layer_layernorm(
  object,
  name = NULL,
  trainable = NULL,
  param_list = list(),
  ...
)
}
\arguments{
\item{object}{Model or layer object.}

\item{name}{Character; An optional name for the layer. Must be unique in a
model.}

\item{trainable}{Logical; whether the layer weights will be updated during
training.}

\item{param_list}{A named list of parameter values used in defining the
layer.
\describe{
\item{\code{epsilon}}{Numeric; small value added to denominators to avoid
dividing by zero. Defaults to \code{1e-12}.}
\item{\code{dtype}}{The data type of the layer output. Defaults to "float32".
Valid values from \code{tensorflow::tf$float32$name}, etc. }
}}
}
\description{
Create a layer that applies layer normalization to the previous layer output.
Note that this layer contains trainable parameters.
}
